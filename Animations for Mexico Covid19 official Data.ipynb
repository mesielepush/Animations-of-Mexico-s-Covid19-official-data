{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import imageio\n",
    "from shutil import copy2, rmtree\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "from constant import *\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\jupol\\Desktop\\TensorTut\\covid\\mex animations\\faltantes'\n",
    "data_dir = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sufx_dict = {\n",
    "    'Deaths': 'Casos_Diarios_Estado_Nacional_Defunciones_2020',\n",
    "    'Confirmed': 'Casos_Diarios_Estado_Nacional_Confirmados_2020',\n",
    "    'Suspicious': 'Casos_Diarios_Estado_Nacional_Sospechosos_2020',\n",
    "    'Negatives': 'Casos_Diarios_Estado_Nacional_Negativos_2020',\n",
    "    'Actives': 'COVID19MEXICO.csv'\n",
    "}\n",
    "\n",
    "def clean_nan(array):\n",
    "    if type(array) == list:\n",
    "        array = np.asarray(array) \n",
    "    not_nan_array = ~ np.isnan(array)\n",
    "    return array[not_nan_array]\n",
    "def make_mp4(state,dtype,max_date):\n",
    "    \n",
    "    for _ in range(30):\n",
    "        copy2(f'plots/{state}/cummulative/{dtype}/{max_date}.jpg', f'plots/{state}/cummulative/{dtype}/{max_date}_{_}.jpg')\n",
    "        copy2(f'plots/{state}/discrete/{dtype}/{max_date}.jpg', f'plots/{state}/discrete/{dtype}/{max_date}_{_}.jpg')\n",
    "\n",
    "    if not os.path.exists(f'results/{state}'):\n",
    "        os.makedirs(f'results/{state}')\n",
    "\n",
    "    cum_images = []\n",
    "\n",
    "    for filename in os.listdir(f'plots/{state}/cummulative/{dtype}'):\n",
    "        cum_images.append(imageio.imread(os.path.join(f'plots/{state}/cummulative/{dtype}',filename)))\n",
    "    imageio.mimsave(f'results/{state}/{dtype}_cummulative_{state}.mp4', cum_images)\n",
    "\n",
    "    dis_images = []\n",
    "\n",
    "    for filename in os.listdir(f'plots/{state}/discrete/{dtype}'):\n",
    "        dis_images.append(imageio.imread(os.path.join(f'plots/{state}/discrete/{dtype}',filename)))\n",
    "    imageio.mimsave(f'results/{state}/{dtype}_discrete_{state}.mp4', dis_images)\n",
    "    \n",
    "    rmtree('plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_discrete(index, plot_index, plot_data, state, file, dtype, max_day,trim):\n",
    "    plt.close('all')\n",
    "    plt.rcParams['figure.figsize'] = (14,6)\n",
    "    plt.rcParams['figure.constrained_layout.use']=True\n",
    "    \n",
    "    plt.title(f'Daily {dtype} Cases for Covid19 in {state}', fontsize = 20)\n",
    "    plt.ylabel(f'Number of {dtype} Cases', fontsize=18)\n",
    "    plt.ylim(0,max_day+(max_day*0.3))\n",
    "    plt.xlim(trim,len(plot_index))\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.bar(plot_index,plot_data, label = f'Number of {dtype} Cases: {max(clean_nan(np.array(plot_data)))}')\n",
    "    plt.suptitle(f'{calendar.month_name[int(file[-8:-6])]} {file[-6:-4]}', fontsize=22)\n",
    "    plt.legend(loc=0,fontsize=20)\n",
    "    plt.savefig(f'plots/{state}/discrete/{dtype}/{file[-12:-8]+\"-\"+file[-8:-6]+\"-\"+file[-6:-4]}.jpg')\n",
    "\n",
    "def plot_single_cummulative(index, plot_index, plot_data, state, file, dtype, max_cummulative,trim):\n",
    "    cummulative_record = []\n",
    "    last_valid = int()\n",
    "    for i in plot_data:\n",
    "\n",
    "        if len(cummulative_record) == 0:\n",
    "            if not np.isnan(i):\n",
    "                cummulative_record.append(i)\n",
    "                last_valid = i\n",
    "            else:\n",
    "                cummulative_record.append(np.nan)\n",
    "                last_valid = 0\n",
    "        else:\n",
    "            if not np.isnan(i):\n",
    "                cummulative_record.append(i+last_valid)\n",
    "                last_valid += i\n",
    "\n",
    "            else:\n",
    "                cummulative_record.append(np.nan)\n",
    "            \n",
    "    plt.close('all')\n",
    "    plt.rcParams['figure.figsize'] = (14,6)\n",
    "    plt.rcParams['figure.constrained_layout.use']=True\n",
    "    \n",
    "    plt.title(f'Cummulative register of {dtype} Cases by Covid19 in {state}', fontsize = 20)\n",
    "    plt.ylabel(f'Number of {dtype} Cases', fontsize=18)\n",
    "    plt.ylim(0,max_cummulative+(max_cummulative*0.3))\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.xlim(trim,len(plot_index))\n",
    "    plt.plot(plot_index,cummulative_record, label=dtype+': '+str(max(clean_nan(cummulative_record))))\n",
    "    plt.suptitle(f'{calendar.month_name[int(file[-8:-6])]} {file[-6:-4]}', fontsize=22)\n",
    "    plt.fill_between(plot_index, cummulative_record, color='b', alpha=.2)\n",
    "    plt.legend(loc=0, fontsize=18)\n",
    "    plt.savefig(f'plots/{state}/cummulative/{dtype}/{file[-12:-8]+\"-\"+file[-8:-6]+\"-\"+file[-6:-4]}.jpg')\n",
    "\n",
    "def plot_multi_discrete(index, plot_index, plot_data, days, dtypes, state, max_day,trim):\n",
    "    \n",
    "    today = calendar.month_name[int(days[0][-8:-6])]+'-'+ days[0][-6:-4]\n",
    "    plt.close('all')\n",
    "    plt.rcParams['figure.figsize'] = (14,6)\n",
    "    plt.rcParams['figure.constrained_layout.use']=True\n",
    "\n",
    "    plt.title(f'Daily {dtypes} Cases for Covid19 in {state}', fontsize = 20)\n",
    "    plt.ylabel(f'Number of Cases', fontsize=18)\n",
    "    plt.ylim(0,max_day+(max_day*0.3))\n",
    "    plt.xlim(trim,len(plot_index))\n",
    "    plt.xticks(rotation=70)\n",
    "    for data in plot_data.keys():\n",
    "        plt.bar(plot_index,plot_data[data], label = f'Number of {data} Cases: {max(clean_nan(np.array(plot_data[data])))}',alpha=0.4)\n",
    "    plt.suptitle(f'{today}', fontsize=22)\n",
    "    plt.legend(loc=0,fontsize=20)\n",
    "    plt.savefig(f'plots/{state}/discrete/{dtypes}/{days[0][-12:-8]}-{days[0][-8:-6]}-{days[0][-6:-4]}.jpg')\n",
    "\n",
    "def plot_multi_cummulative(index, plot_index, plot_data, days, dtypes, state, max_cummulative,trim):\n",
    "    \n",
    "    today = calendar.month_name[int(days[0][-8:-6])]+'-'+ days[0][-6:-4]\n",
    "    cum_data = {key:[] for key in plot_data.keys()}\n",
    "    \n",
    "    for key in plot_data.keys():\n",
    "    \n",
    "        last_valid = int()\n",
    "        for i in plot_data[key]:\n",
    "\n",
    "            if len(cum_data[key]) == 0:\n",
    "                if not np.isnan(i):\n",
    "                    cum_data[key].append(i)\n",
    "                    last_valid = i\n",
    "                else:\n",
    "                    cum_data[key].append(np.nan)\n",
    "                    last_valid = 0\n",
    "            else:\n",
    "                if not np.isnan(i):\n",
    "                    cum_data[key].append(i+last_valid)\n",
    "                    last_valid += i\n",
    "\n",
    "                else:\n",
    "                    cum_data[key].append(np.nan)\n",
    "            \n",
    "    plt.close('all')\n",
    "    plt.rcParams['figure.figsize'] = (14,6)\n",
    "    plt.rcParams['figure.constrained_layout.use']=True\n",
    "    \n",
    "    plt.title(f'Cummulative register of {dtypes} Cases by Covid19 in {state}', fontsize = 20)\n",
    "    plt.ylabel(f'Number of {dtypes} Cases', fontsize=18)\n",
    "    plt.ylim(0,max_cummulative+(max_cummulative*0.3))\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.xlim(trim,len(plot_index))\n",
    "    for key in cum_data:\n",
    "        plt.plot(plot_index,cum_data[key], label=key+': '+str(max(clean_nan(cum_data[key]))))\n",
    "        plt.fill_between(plot_index, cum_data[key], alpha=.2)\n",
    "        \n",
    "    plt.suptitle(f'{calendar.month_name[int(days[0][-8:-6])]} {days[0][-6:-4]}', fontsize=22)\n",
    "    plt.legend(loc=0, fontsize=18)\n",
    "    \n",
    "    plt.savefig(f'plots/{state}/cummulative/{dtypes}/{days[0][-12:-8]}-{days[0][-8:-6]}-{days[0][-6:-4]}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(index, plot_index, state, file, dtype, max_day, max_cummulative,trim):\n",
    "    \n",
    "    if not os.path.exists(f'plots/{state}/cummulative/{dtype}'):\n",
    "        os.makedirs(f'plots/{state}/cummulative/{dtype}')\n",
    "        \n",
    "    if not os.path.exists(f'plots/{state}/discrete/{dtype}'):\n",
    "        os.makedirs(f'plots/{state}/discrete/{dtype}')\n",
    "        \n",
    "    data = pd.read_csv(os.path.join(data_path,file))\n",
    "    data = data[data['nombre'] == state]\n",
    "    dates = pd.to_datetime(data.columns[3:], dayfirst=True)\n",
    "    \n",
    "    plot_data = []\n",
    "                       \n",
    "    for day in index:\n",
    "        try:\n",
    "            plot_data.append(data[str(day)[-11:-9]+str(day)[-15:-11]+str(day)[:4]].values[0])\n",
    "        except:\n",
    "            plot_data.append(np.nan)\n",
    "    \n",
    "    plot_single_discrete(index, plot_index, plot_data, state, file, dtype, max_day,trim)\n",
    "    \n",
    "    plot_single_cummulative(index, plot_index, plot_data, state, file, dtype, max_cummulative,trim)    \n",
    "    \n",
    "    print(f'Plots of {dtype} ready for day: {calendar.month_name[int(file[-8:-6])]} {file[-6:-4]}')\n",
    "\n",
    "def make_multi_plots(index, plot_index, state, days, sufx_items, max_day, max_cummulative,trim,dtypes):\n",
    "    \n",
    "    if not os.path.exists(f'plots/{state}/cummulative/{dtypes}'):\n",
    "        os.makedirs(f'plots/{state}/cummulative/{dtypes}')\n",
    "        \n",
    "    if not os.path.exists(f'plots/{state}/discrete/{dtypes}'):\n",
    "        os.makedirs(f'plots/{state}/discrete/{dtypes}')\n",
    "    \n",
    "    data = [pd.read_csv(os.path.join(data_path,x)) for x in days]\n",
    "    data = [x[x['nombre'] == state] for x in data]\n",
    "        \n",
    "    plot_data = {key:[] for key in sufx_items.keys()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ind, key in enumerate(plot_data.keys()):\n",
    "        for day in index:\n",
    "            try:\n",
    "                plot_data[key].append(data[ind][str(day)[-11:-9]+str(day)[-15:-11]+str(day)[:4]].values[0])\n",
    "            except:\n",
    "                plot_data[key].append(np.nan)\n",
    "    \n",
    "    plot_multi_discrete(index, plot_index, plot_data, days, dtypes, state, max_day,trim)\n",
    "    plot_multi_cummulative(index, plot_index, plot_data, days, dtypes, state, max_cummulative,trim)\n",
    "    print(f'Plots of {dtypes} ready for day: {calendar.month_name[int(days[0][-8:-6])]} {days[0][-6:-4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_indexes(sufx, data_dir, state):\n",
    "\n",
    "    newest_date = max(set([ pd.to_datetime(f'2020-{date[-8:-6]}-{date[-6:-4]}',format = \"%Y/%m/%d\") for date in data_dir if date.startswith(sufx)]))\n",
    "    oldest_date = min(set([ pd.to_datetime(f'2020-{date[-8:-6]}-{date[-6:-4]}',format = \"%Y/%m/%d\") for date in data_dir if date.startswith(sufx)]))\n",
    "\n",
    "    newest_date = pd.read_csv(os.path.join( data_path, sufx + str(newest_date)[-14:-12]+str(newest_date)[-11:-9]+'.csv') )\n",
    "    oldest_date = pd.read_csv(os.path.join( data_path, sufx + str(oldest_date)[-14:-12]+str(oldest_date)[-11:-9]+'.csv') )\n",
    "\n",
    "    max_day = max(newest_date[newest_date['nombre'] == state].values[0][3:])\n",
    "    max_cummulative = sum(newest_date[newest_date['nombre'] == state].values[0][3:])\n",
    "    \n",
    "    index = pd.date_range(start= pd.to_datetime(oldest_date.columns[3], dayfirst=True), end = pd.to_datetime(newest_date.columns[-1], dayfirst=True))\n",
    "    plot_index = [calendar.month_name[int(str(x)[5:-12])] + ' / ' + str(x)[8:-9]  for x in index]\n",
    "        \n",
    "    return index, plot_index, max_day, max_cummulative\n",
    "\n",
    "def get_multi_indexes(files, data_dir, state, sufx_items):\n",
    "    \n",
    "    newest_date = max(set([ pd.to_datetime(f'2020-{date[-8:-6]}-{date[-6:-4]}',format = \"%Y/%m/%d\") for date in files[list(sufx_items.keys())[0]]]))\n",
    "    oldest_date = min(set([ pd.to_datetime(f'2020-{date[-8:-6]}-{date[-6:-4]}',format = \"%Y/%m/%d\") for date in files[list(sufx_items.keys())[0]]]))\n",
    "    \n",
    "    longest_data_check = 0\n",
    "    longest_data = ''\n",
    "    max_day = 0\n",
    "    max_cummulative = 0\n",
    "    \n",
    "    for dtype in files.keys():\n",
    "        \n",
    "        data_check = pd.read_csv(os.path.join( data_path, sufx_items[dtype] + str(newest_date)[-14:-12]+str(newest_date)[-11:-9]+'.csv'))\n",
    "        max_discrete = max(data_check[data_check['nombre'] == state].values[0][3:])\n",
    "        sum_cummulative = sum(data_check[data_check['nombre'] == state].values[0][3:])\n",
    "        \n",
    "        if len(data_check.columns[3:]) > longest_data_check:\n",
    "            longest_data_check == len(data_check.columns[3:])\n",
    "            longest_data = data_check[data_check['nombre'] == state]\n",
    "            \n",
    "        if  max_discrete > max_day:\n",
    "            max_day = max_discrete\n",
    "        if sum_cummulative > max_cummulative:\n",
    "            max_cummulative = sum_cummulative\n",
    "    \n",
    "    index = pd.date_range(start= pd.to_datetime(longest_data.columns[3], dayfirst=True), end = pd.to_datetime(longest_data.columns[-1], dayfirst=True))\n",
    "    plot_index = [calendar.month_name[int(str(x)[5:-12])] + ' / ' + str(x)[8:-9]  for x in index]\n",
    "    \n",
    "    return index, plot_index, max_day, max_cummulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_animation(data_dir, dtype, state, trim=0):\n",
    "    \n",
    "    if type(dtype) == list :\n",
    "        \n",
    "        sufx_items = {key:sufx_dict[key] for key in dtype}\n",
    "        \n",
    "        dtypes_list = [x for x in sufx_items.keys()]\n",
    "        dtypes=''\n",
    "        for i in dtypes_list:\n",
    "            dtypes += i+' '\n",
    "        dtypes = dtypes[:-1]\n",
    "        \n",
    "        files = {}\n",
    "        for key in sufx_items.keys():\n",
    "            files[key] = [file for file in data_dir if file.startswith(sufx_items[key])]\n",
    "        \n",
    "        assert len(set([len(files[key]) for key in files.keys()])) == 1\n",
    "        \n",
    "        index, plot_index, max_day, max_cummulative = get_multi_indexes(files, data_dir, state, sufx_items)\n",
    "        \n",
    "        for instance in range(len(files[dtype[0]])):\n",
    "            days = []\n",
    "            for key in files.keys():\n",
    "                days.append(files[key][instance])\n",
    "            \n",
    "            make_multi_plots(index, plot_index, state, days, sufx_items, max_day, max_cummulative,trim, dtypes)\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        plots  = [x[:-4] for x in os.listdir(f'plots/{state}/cummulative/{dtypes}')]\n",
    "        max_date = str(max(pd.to_datetime(plots)))[:10]\n",
    "        \n",
    "        make_mp4(state,dtypes,max_date)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        sufx = sufx_dict[dtype]\n",
    "    \n",
    "        index, plot_index, max_day, max_cummulative = get_indexes(sufx, data_dir, state)\n",
    "        files = [file for file in data_dir if file.startswith(sufx)]\n",
    "\n",
    "        for file in files:\n",
    "            make_plots(index, plot_index, state, file, dtype, max_day, max_cummulative,trim)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        plots  = [x[:-4] for x in os.listdir(f'plots/{state}/cummulative/{dtype}')]\n",
    "        max_date = str(max(pd.to_datetime(plots)))[:10]\n",
    "        \n",
    "        make_mp4(state,dtype,max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_animation(data_dir = data_dir,\n",
    "               dtype     = 'Deaths',\n",
    "               state    = 'Nacional',\n",
    "               trim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_animation(data_dir = data_dir,\n",
    "               dtype     = ['Confirmed','Suspicious'],\n",
    "               state    = 'Nacional',\n",
    "               trim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_animation(data_dir = data_dir,\n",
    "               dtype     = ['Negatives','Confirmed'],\n",
    "               state    = 'Nacional',\n",
    "               trim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dir = r'C:\\Users\\jupol\\Desktop\\TensorTut\\covid\\pass'\n",
    "pass_dir = os.listdir(r'C:\\Users\\jupol\\Desktop\\TensorTut\\covid\\pass')\n",
    "dates_pass = {date[4:6]+'-'+date[2:4]+'-'+'20'+date[:2] : date for date in pass_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_states = {\n",
    "    'Defunciones': 'Casos_Diarios_Estado_Nacional_Defunciones_',\n",
    "    'Confirmados': 'Casos_Diarios_Estado_Nacional_Confirmados_',\n",
    "    'Negativos'  : 'Casos_Diarios_Estado_Nacional_Negativos_',\n",
    "    'Sospechosos': 'Casos_Diarios_Estado_Nacional_Sospechosos_'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_data_from_patients_files():\n",
    "    result = {}\n",
    "    for state in cdns_states:\n",
    "        result[state] = {}\n",
    "        for dtype in dtypes_states.keys():\n",
    "\n",
    "            result[state][dtype] = {} \n",
    "            base  = pd.read_csv(os.path.join(r'C:\\Users\\jupol\\Desktop\\TensorTut\\covid\\legacyCovidMexico', f'{dtypes_states[dtype]}20200518.csv'))\n",
    "            state_data = base[base['nombre'] == state]\n",
    "            for today in dates_pass.keys():\n",
    "\n",
    "                result[state][dtype][today] = []\n",
    "                print(f'Begining {state}_{today}_{dtype}')\n",
    "                if dtype == 'Defunciones':\n",
    "\n",
    "                    today_result = []\n",
    "\n",
    "                    patients = change_df_names(pd.read_csv(os.path.join( d_dir, dates_pass[today] ), encoding='ANSI'))\n",
    "                    if state != 'Nacional':\n",
    "                        patients = patients[patients['treated_at'] == inverse_dict_for_name_states[state] ]\n",
    "                    patients = patients[patients['day_of_death'] != '9999-99-99' ]\n",
    "                    patients = patients[patients['result'] == 1]\n",
    "                    patients = pd.to_datetime(patients['day_of_death'].copy())\n",
    "\n",
    "                    if len(patients) == 0:\n",
    "                        min_date = pd.to_datetime(state_data.columns[3],dayfirst=True)\n",
    "                    else:\n",
    "                        min_date = min(min(patients),pd.to_datetime(state_data.columns[3],dayfirst=True))\n",
    "\n",
    "                    local_index = pd.date_range(start = min_date, end = pd.to_datetime(today, dayfirst=True))\n",
    "\n",
    "                    for day in pd.to_datetime(local_index):\n",
    "                        try:\n",
    "                            today_result.append(list(patients).count(day))\n",
    "\n",
    "                        except:\n",
    "                            today_result.append(0)\n",
    "\n",
    "                    result[state][dtype][today] = today_result\n",
    "                    result[state][dtype][today+'_localindex'] = local_index\n",
    "                    print(f' Done for: {state}-{dtype}-{today} ')\n",
    "\n",
    "                if dtype == 'Confirmados':\n",
    "\n",
    "                    today_result = []\n",
    "\n",
    "                    patients = change_df_names(pd.read_csv(os.path.join( d_dir, dates_pass[today] ), encoding='ANSI'))\n",
    "                    if state != 'Nacional':\n",
    "                        patients = patients[patients['treated_at'] == inverse_dict_for_name_states[state] ]\n",
    "                    patients = patients[patients['result'] == 1 ]\n",
    "                    patients = pd.to_datetime(patients['onset_symptoms'].copy())\n",
    "\n",
    "                    if len(patients) == 0:\n",
    "                        min_date = pd.to_datetime(state_data.columns[3],dayfirst=True)\n",
    "                    else:\n",
    "                        min_date = min(min(patients),pd.to_datetime(state_data.columns[3],dayfirst=True))\n",
    "\n",
    "                    local_index = pd.date_range(start = min_date, end = pd.to_datetime(today, dayfirst=True))\n",
    "\n",
    "                    for day in pd.to_datetime(local_index):\n",
    "                        try:\n",
    "                            today_result.append(list(patients).count(day))\n",
    "\n",
    "                        except:\n",
    "                            today_result.append(0)\n",
    "\n",
    "                    result[state][dtype][today] = today_result\n",
    "                    result[state][dtype][today+'_localindex'] = local_index\n",
    "                    print(f' Done for: {state}-{dtype}-{today} ')\n",
    "\n",
    "                if dtype == 'Negativos':\n",
    "\n",
    "                    today_result = []\n",
    "\n",
    "                    patients = change_df_names(pd.read_csv(os.path.join( d_dir, dates_pass[today] ), encoding='ANSI'))\n",
    "                    if state != 'Nacional':\n",
    "                        patients = patients[patients['treated_at'] == inverse_dict_for_name_states[state] ]\n",
    "                    patients = patients[patients['result'] == 2 ]\n",
    "                    patients = pd.to_datetime(patients['onset_symptoms'].copy())\n",
    "                    if len(patients) == 0:\n",
    "                        min_date = pd.to_datetime(state_data.columns[3],dayfirst=True)\n",
    "                    else:\n",
    "                        min_date = min(min(patients),pd.to_datetime(state_data.columns[3],dayfirst=True))\n",
    "                    local_index = pd.date_range(start = min_date, end = pd.to_datetime(today, dayfirst=True))\n",
    "\n",
    "                    for day in pd.to_datetime(local_index):\n",
    "                        try:\n",
    "                            today_result.append(list(patients).count(day))\n",
    "\n",
    "                        except:\n",
    "                            today_result.append(0)\n",
    "\n",
    "                    result[state][dtype][today] = today_result\n",
    "                    result[state][dtype][today+'_localindex'] = local_index\n",
    "                    print(f' Done for: {state}-{dtype}-{today} ')\n",
    "\n",
    "\n",
    "                if dtype == 'Sospechosos':\n",
    "\n",
    "                    today_result = []\n",
    "\n",
    "                    patients = change_df_names(pd.read_csv(os.path.join( d_dir, dates_pass[today] ), encoding='ANSI'))\n",
    "                    if state != 'Nacional':\n",
    "                        patients = patients[patients['treated_at'] == inverse_dict_for_name_states[state] ]\n",
    "                    patients = patients[patients['result'] == 3 ]\n",
    "                    patients = pd.to_datetime(patients['onset_symptoms'].copy())\n",
    "\n",
    "                    if len(patients) == 0:\n",
    "                        min_date = pd.to_datetime(state_data.columns[3],dayfirst=True)\n",
    "                    else:\n",
    "                        min_date = min(min(patients),pd.to_datetime(state_data.columns[3],dayfirst=True))\n",
    "\n",
    "                    local_index = pd.date_range(start = min_date, end = pd.to_datetime(today, dayfirst=True))\n",
    "\n",
    "                    for day in pd.to_datetime(local_index):\n",
    "                        try:\n",
    "                            today_result.append(list(patients).count(day))\n",
    "\n",
    "                        except:\n",
    "                            today_result.append(0)\n",
    "\n",
    "                    result[state][dtype][today] = today_result\n",
    "                    result[state][dtype][today+'_localindex'] = local_index\n",
    "                    print(f' Done for: {state}-{dtype}-{today} ')\n",
    "    joblib.dump(result,'result.pkl')\n",
    "    for dtype in dtypes_states.keys():\n",
    "        for date in dates_pass.keys():\n",
    "            base  = pd.read_csv(os.path.join(r'C:\\Users\\jupol\\Desktop\\TensorTut\\covid\\legacyCovidMexico', f'{dtypes_states[dtype]}20200518.csv'))\n",
    "            data = {}\n",
    "            for state in result.keys():\n",
    "\n",
    "                data[state] = {}\n",
    "                data[state] = result[state][dtype][date]\n",
    "\n",
    "            max_len = max([len(data[x]) for x in result.keys()])\n",
    "\n",
    "            for state in result.keys():\n",
    "                if len(data[state]) != max_len:\n",
    "                    data[state] = [0]*( max_len - len(data[state]) ) +data[state]\n",
    "\n",
    "            today = pd.to_datetime(date, dayfirst=True)\n",
    "            data = pd.DataFrame.from_dict(data).T\n",
    "            index = pd.date_range(start=(today - timedelta(days=len(data.columns)-1) ), end = today)\n",
    "            index=[str(date)[8:10]+'-'+str(date)[5:7]+'-'+str(date)[:4] for date in index]\n",
    "            data.columns = index\n",
    "            data['nombre'] = data.index\n",
    "            data['poblacion'] = base['poblacion'].values.copy()\n",
    "            data['cve_ent'] = base['cve_ent'].values.copy()\n",
    "            order = ['cve_ent','poblacion', 'nombre']+index\n",
    "            data = data[order]\n",
    "            data = data.reset_index(drop = True)\n",
    "\n",
    "            data.to_csv(f'faltantes/{dtypes_states[dtype]}{str(today)[:4]+str(today)[5:7]+str(today)[8:10]}.csv', encoding='ANSI',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining AGUASCALIENTES_11-06-2020_Defunciones\n",
      " Done for: AGUASCALIENTES-Defunciones-11-06-2020 \n",
      "Begining AGUASCALIENTES_11-06-2020_Confirmados\n",
      " Done for: AGUASCALIENTES-Confirmados-11-06-2020 \n",
      "Begining AGUASCALIENTES_11-06-2020_Negativos\n",
      " Done for: AGUASCALIENTES-Negativos-11-06-2020 \n",
      "Begining AGUASCALIENTES_11-06-2020_Sospechosos\n",
      " Done for: AGUASCALIENTES-Sospechosos-11-06-2020 \n",
      "Begining BAJA CALIFORNIA_11-06-2020_Defunciones\n",
      " Done for: BAJA CALIFORNIA-Defunciones-11-06-2020 \n",
      "Begining BAJA CALIFORNIA_11-06-2020_Confirmados\n",
      " Done for: BAJA CALIFORNIA-Confirmados-11-06-2020 \n",
      "Begining BAJA CALIFORNIA_11-06-2020_Negativos\n",
      " Done for: BAJA CALIFORNIA-Negativos-11-06-2020 \n",
      "Begining BAJA CALIFORNIA_11-06-2020_Sospechosos\n",
      " Done for: BAJA CALIFORNIA-Sospechosos-11-06-2020 \n",
      "Begining BAJA CALIFORNIA SUR_11-06-2020_Defunciones\n",
      " Done for: BAJA CALIFORNIA SUR-Defunciones-11-06-2020 \n",
      "Begining BAJA CALIFORNIA SUR_11-06-2020_Confirmados\n",
      " Done for: BAJA CALIFORNIA SUR-Confirmados-11-06-2020 \n",
      "Begining BAJA CALIFORNIA SUR_11-06-2020_Negativos\n",
      " Done for: BAJA CALIFORNIA SUR-Negativos-11-06-2020 \n",
      "Begining BAJA CALIFORNIA SUR_11-06-2020_Sospechosos\n",
      " Done for: BAJA CALIFORNIA SUR-Sospechosos-11-06-2020 \n",
      "Begining CAMPECHE_11-06-2020_Defunciones\n",
      " Done for: CAMPECHE-Defunciones-11-06-2020 \n",
      "Begining CAMPECHE_11-06-2020_Confirmados\n",
      " Done for: CAMPECHE-Confirmados-11-06-2020 \n",
      "Begining CAMPECHE_11-06-2020_Negativos\n",
      " Done for: CAMPECHE-Negativos-11-06-2020 \n",
      "Begining CAMPECHE_11-06-2020_Sospechosos\n",
      " Done for: CAMPECHE-Sospechosos-11-06-2020 \n",
      "Begining CHIAPAS_11-06-2020_Defunciones\n",
      " Done for: CHIAPAS-Defunciones-11-06-2020 \n",
      "Begining CHIAPAS_11-06-2020_Confirmados\n",
      " Done for: CHIAPAS-Confirmados-11-06-2020 \n",
      "Begining CHIAPAS_11-06-2020_Negativos\n",
      " Done for: CHIAPAS-Negativos-11-06-2020 \n",
      "Begining CHIAPAS_11-06-2020_Sospechosos\n",
      " Done for: CHIAPAS-Sospechosos-11-06-2020 \n",
      "Begining CHIHUAHUA_11-06-2020_Defunciones\n",
      " Done for: CHIHUAHUA-Defunciones-11-06-2020 \n",
      "Begining CHIHUAHUA_11-06-2020_Confirmados\n",
      " Done for: CHIHUAHUA-Confirmados-11-06-2020 \n",
      "Begining CHIHUAHUA_11-06-2020_Negativos\n",
      " Done for: CHIHUAHUA-Negativos-11-06-2020 \n",
      "Begining CHIHUAHUA_11-06-2020_Sospechosos\n",
      " Done for: CHIHUAHUA-Sospechosos-11-06-2020 \n",
      "Begining DISTRITO FEDERAL_11-06-2020_Defunciones\n",
      " Done for: DISTRITO FEDERAL-Defunciones-11-06-2020 \n",
      "Begining DISTRITO FEDERAL_11-06-2020_Confirmados\n"
     ]
    }
   ],
   "source": [
    "create_data_from_patients_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
